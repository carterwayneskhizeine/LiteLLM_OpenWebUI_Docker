services:
  litellm:
    image: ghcr.io/berriai/litellm:main-latest
    #########################################
    ## Uncomment these lines to start proxy with a config.yaml file ##
    # volumes:
    #  - ./config.yaml:/app/config.yaml
    # command:
    #  - "--config=/app/config.yaml"
    ##############################################
    ports:
      - "0.0.0.0:4000:4000" # Map the container port to the host, change the host port if necessary
    environment:
      DATABASE_URL: "postgresql://llmproxy:dbpassword9090@db:5432/litellm"
      STORE_MODEL_IN_DB: "True" # allows adding models to proxy via UI
      LITELLM_ENABLE_PROMETHEUS: "True" # Enable /metrics endpoint for Prometheus
      #HTTP_PROXY: "http://172.31.219.189:8964"  # 使用ShellCrash代理
      #HTTPS_PROXY: "http://172.31.219.189:8964"  # 使用ShellCrash代理
      #NO_PROXY: "localhost,127.0.0.1,db,open-webui"  # 不代理本地服务
    env_file:
      - .env # Load local .env file
    volumes:
      # 挂载项目文件夹中的配置文件
      - ./litellmconfig.yaml:/app/config.yaml
    command:
      - "--config=/app/config.yaml"
    depends_on:
      - db  # Indicates that this service depends on the 'db' service, ensuring 'db' starts first
    healthcheck:  # Defines the health check configuration for the container
      test: [ "CMD-SHELL", "wget --no-verbose --tries=1 http://localhost:4000/health/liveliness || exit 1" ]  # Command to execute for health check
      interval: 30s  # Perform health check every 30 seconds
      timeout: 10s   # Health check command times out after 10 seconds
      retries: 3     # Retry up to 3 times if health check fails
      start_period: 40s  # Wait 40 seconds after container start before beginning health checks

  db:
    image: postgres:16
    restart: always
    container_name: litellm_db
    environment:
      POSTGRES_DB: litellm
      POSTGRES_USER: llmproxy
      POSTGRES_PASSWORD: dbpassword9090
    ports:
      - "0.0.0.0:5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data # Persists Postgres data across container restarts
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -d litellm -U llmproxy"]
      interval: 1s
      timeout: 5s
      retries: 10

  open-webui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: open-webui
    ports:
      - "0.0.0.0:9036:8080"
    volumes:
      - open-webui:/app/backend/data
    environment:
      - OPENAI_API_BASE_URLS=http://litellm:4000/v1
      - OPENAI_API_KEYS=sk-Virtual-key  # Replace with your actual LiteLLM Virtual key from http://localhost:4000/ui create a new key
      - WEBUI_SECRET_KEY=
    depends_on:
      - litellm
    extra_hosts:
      - host.docker.internal:host-gateway
    restart: always

volumes:
  postgres_data:
    name: litellm_postgres_data # Named volume for Postgres data persistence
  open-webui: